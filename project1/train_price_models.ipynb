{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading cleaned data from: /Users/doananh/Documents/đồ án DS/data_motobikes_clean.csv\n",
            "  Loaded 7208 rows\n",
            "Loading preprocessor from: /Users/doananh/Documents/đồ án DS/artifacts/preprocessor.joblib\n",
            "\n",
            "Target (gia_vnd_final) statistics:\n",
            "  Total rows: 7208\n",
            "  Missing (NaN): 2\n",
            "  Zero or negative: 1\n",
            "  Valid (> 0): 7205\n",
            "\n",
            "After filtering: 7205 rows (removed 3 rows with missing/invalid target)\n",
            "\n",
            "Training 2 models with 5-fold CV...\n",
            "\n",
            "Training rf...\n",
            "  rf - MAE: 60672658.90, R²: -145.0436\n",
            "\n",
            "Training hgbr...\n",
            "  hgbr - MAE: 134754490.84, R²: -238.4657\n",
            "\n",
            "==================================================\n",
            "Saved CV results to: /Users/doananh/Documents/đồ án DS/models/price_cv_results.csv\n",
            "  model      MAE_mean       MAE_std     RMSE_mean      RMSE_std     R2_mean  \\\n",
            "0    rf  6.067266e+07  2.586947e+07  1.381737e+09  1.132382e+09 -145.043598   \n",
            "1  hgbr  1.347545e+08  1.643667e+07  1.492230e+09  1.061491e+09 -238.465709   \n",
            "\n",
            "       R2_std    MAPE_mean      MAPE_std  \n",
            "0   87.582280  6966.775861  12104.440811  \n",
            "1  191.555846  9096.418655  10500.565985  \n",
            "\n",
            "Best model (lowest MAE): rf\n",
            "Fitting final model on full dataset...\n",
            "Done!\n",
            "\n",
            "Saved best price model to: /Users/doananh/Documents/đồ án DS/models/price_model.joblib\n"
          ]
        }
      ],
      "source": [
        "# Train Price Models: Dummy, RF, HGBR\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import KFold, cross_validate\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingRegressor\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from scipy import sparse\n",
        "import joblib\n",
        "\n",
        "# Transformer to convert sparse to dense (needed for HistGradientBoostingRegressor)\n",
        "class SparseToDense(BaseEstimator, TransformerMixin):\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    def transform(self, X):\n",
        "        if sparse.issparse(X):\n",
        "            return X.toarray()\n",
        "        return X\n",
        "\n",
        "DATA_DIR = Path('/Users/doananh/Documents/đồ án DS')\n",
        "CLEAN_FILE = DATA_DIR / 'data_motobikes_clean.csv'\n",
        "ARTIFACT_DIR = DATA_DIR / 'artifacts'\n",
        "MODEL_DIR = DATA_DIR / 'models'\n",
        "MODEL_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# Check dependencies\n",
        "if not CLEAN_FILE.exists():\n",
        "    raise FileNotFoundError(f\"File not found: {CLEAN_FILE}\\nPlease run 'preprocess_validate.ipynb' first.\")\n",
        "preprocessor_path = ARTIFACT_DIR / 'preprocessor.joblib'\n",
        "if not preprocessor_path.exists():\n",
        "    raise FileNotFoundError(f\"File not found: {preprocessor_path}\\nPlease run 'prep_preprocessor.ipynb' first.\")\n",
        "\n",
        "print(f\"Loading cleaned data from: {CLEAN_FILE}\")\n",
        "Df = pd.read_csv(CLEAN_FILE, low_memory=False)\n",
        "print(f\"  Loaded {len(Df)} rows\")\n",
        "\n",
        "print(f\"Loading preprocessor from: {preprocessor_path}\")\n",
        "pre = joblib.load(preprocessor_path)\n",
        "preprocessor = pre['preprocessor']\n",
        "NUMERIC_FEATURES = pre['numeric_features']\n",
        "CATEGORICAL_FEATURES = pre['categorical_features']\n",
        "TARGET = pre['target']\n",
        "\n",
        "X = Df[NUMERIC_FEATURES + CATEGORICAL_FEATURES]\n",
        "y = Df[TARGET].astype(float)\n",
        "\n",
        "# Check target statistics\n",
        "print(f\"\\nTarget ({TARGET}) statistics:\")\n",
        "print(f\"  Total rows: {len(y)}\")\n",
        "print(f\"  Missing (NaN): {y.isna().sum()}\")\n",
        "print(f\"  Zero or negative: {(y <= 0).sum()}\")\n",
        "print(f\"  Valid (> 0): {(y > 0).sum()}\")\n",
        "\n",
        "# Remove rows with missing/invalid target (required for training)\n",
        "mask_valid = y.notna() & (y > 0)\n",
        "X = X[mask_valid].copy()\n",
        "y = y[mask_valid].copy()\n",
        "print(f\"\\nAfter filtering: {len(X)} rows (removed {len(Df) - len(X)} rows with missing/invalid target)\")\n",
        "\n",
        "# Verify no NaN in y\n",
        "assert y.notna().all(), f\"Still found {y.isna().sum()} NaN values in y after filtering!\"\n",
        "assert (y > 0).all(), f\"Still found {(y <= 0).sum()} non-positive values in y after filtering!\"\n",
        "\n",
        "# Helpers\n",
        "\n",
        "def mape(y_true, y_pred):\n",
        "    y_true = np.asarray(y_true)\n",
        "    y_pred = np.asarray(y_pred)\n",
        "    mask = y_true > 0\n",
        "    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask]))\n",
        "\n",
        "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "candidates = {\n",
        "    'rf': RandomForestRegressor(\n",
        "        n_estimators=600,\n",
        "        max_depth=25,\n",
        "        min_samples_leaf=2,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    ),\n",
        "    'hgbr': HistGradientBoostingRegressor(\n",
        "        learning_rate=0.05,\n",
        "        max_depth=10,\n",
        "        max_iter=800,\n",
        "        min_samples_leaf=15,\n",
        "        random_state=42\n",
        "    )\n",
        "}\n",
        "\n",
        "rows = []\n",
        "results_per_model = {}\n",
        "\n",
        "print(f\"\\nTraining {len(candidates)} models with {cv.n_splits}-fold CV...\")\n",
        "for name, model in candidates.items():\n",
        "    print(f\"\\nTraining {name}...\")\n",
        "    # HGBR requires dense data, others can handle sparse\n",
        "    if name == 'hgbr':\n",
        "        pipe = Pipeline([\n",
        "            ('pre', preprocessor),\n",
        "            ('sparse_to_dense', SparseToDense()),\n",
        "            ('model', model)\n",
        "        ])\n",
        "    else:\n",
        "        pipe = Pipeline([\n",
        "            ('pre', preprocessor),\n",
        "            ('model', model)\n",
        "        ])\n",
        "    scores = cross_validate(\n",
        "        pipe, X, y,\n",
        "        cv=cv,\n",
        "        scoring=('neg_mean_absolute_error','neg_root_mean_squared_error','r2'),\n",
        "        return_train_score=False,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    # Fit once to compute MAPE on held-out folds is tricky; approximate with CV predictions optional.\n",
        "    # Here we compute MAPE via a manual loop for precision.\n",
        "    maes, rmses, r2s, mapes = [], [], [], []\n",
        "    for tr_idx, te_idx in cv.split(X):\n",
        "        Xtr, Xte = X.iloc[tr_idx], X.iloc[te_idx]\n",
        "        ytr, yte = y.iloc[tr_idx], y.iloc[te_idx]\n",
        "        pipe.fit(Xtr, ytr)\n",
        "        yhat = pipe.predict(Xte)\n",
        "        maes.append(mean_absolute_error(yte, yhat))\n",
        "        rmses.append(np.sqrt(mean_squared_error(yte, yhat)))\n",
        "        r2s.append(r2_score(yte, yhat))\n",
        "        mapes.append(mape(yte, yhat))\n",
        "    row = {\n",
        "        'model': name,\n",
        "        'MAE_mean': np.mean(maes), 'MAE_std': np.std(maes),\n",
        "        'RMSE_mean': np.mean(rmses), 'RMSE_std': np.std(rmses),\n",
        "        'R2_mean': np.mean(r2s), 'R2_std': np.std(r2s),\n",
        "        'MAPE_mean': np.mean(mapes), 'MAPE_std': np.std(mapes)\n",
        "    }\n",
        "    rows.append(row)\n",
        "    results_per_model[name] = row\n",
        "    print(f\"  {name} - MAE: {row['MAE_mean']:.2f}, R²: {row['R2_mean']:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "cv_df = pd.DataFrame(rows).sort_values('MAE_mean')\n",
        "cv_path = MODEL_DIR / 'price_cv_results.csv'\n",
        "cv_df.to_csv(cv_path, index=False)\n",
        "print('Saved CV results to:', cv_path)\n",
        "print(cv_df)\n",
        "\n",
        "# Select best by MAE\n",
        "best_name = cv_df.iloc[0]['model']\n",
        "print(f\"\\nBest model (lowest MAE): {best_name}\")\n",
        "best_model = candidates[best_name]\n",
        "# Add sparse_to_dense if best model is HGBR\n",
        "if best_name == 'hgbr':\n",
        "    final_pipe = Pipeline([\n",
        "        ('pre', preprocessor),\n",
        "        ('sparse_to_dense', SparseToDense()),\n",
        "        ('model', best_model)\n",
        "    ])\n",
        "else:\n",
        "    final_pipe = Pipeline([\n",
        "        ('pre', preprocessor),\n",
        "        ('model', best_model)\n",
        "    ])\n",
        "print(\"Fitting final model on full dataset...\")\n",
        "final_pipe.fit(X, y)\n",
        "print(\"Done!\")\n",
        "\n",
        "best_path = MODEL_DIR / 'price_model.joblib'\n",
        "joblib.dump({'model': final_pipe, 'cv_results': cv_df.to_dict(orient='records'), 'best_name': best_name}, best_path)\n",
        "print(f'\\nSaved best price model to: {best_path}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "fugue_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
