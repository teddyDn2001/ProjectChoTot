{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading price model from: /Users/doananh/Documents/đồ án DS/models/price_model.joblib\n",
            "Price model loaded. Best model: rf\n",
            "\n",
            "1) Computing residual-based anomalies...\n",
            "   Predicting prices...\n",
            "   Found 361 anomalies (top 5.0% by |pct_err|)\n",
            "   Saved residual-based anomalies to: /Users/doananh/Documents/đồ án DS/anomaly_outputs/anomalies_residual.csv\n",
            "\n",
            "2) Training IsolationForest anomaly detector...\n",
            "   Transforming features...\n",
            "   Fitting IsolationForest (contamination=0.05)...\n",
            "   Found 361 anomalies (top 5% by iso_score)\n",
            "   Saved IsolationForest model to: /Users/doananh/Documents/đồ án DS/models/iso_model.joblib\n",
            "   Saved IsolationForest anomalies to: /Users/doananh/Documents/đồ án DS/anomaly_outputs/anomalies_isolation.csv\n",
            "\n",
            "==================================================\n",
            "Anomaly detection completed!\n"
          ]
        }
      ],
      "source": [
        "# Train Anomaly Models: Residual-based and IsolationForest\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.pipeline import Pipeline\n",
        "import joblib\n",
        "\n",
        "DATA_DIR = Path('/Users/doananh/Documents/đồ án DS')\n",
        "CLEAN_FILE = DATA_DIR / 'data_motobikes_clean.csv'\n",
        "ARTIFACT_DIR = DATA_DIR / 'artifacts'\n",
        "MODEL_DIR = DATA_DIR / 'models'\n",
        "OUT_DIR = DATA_DIR / 'anomaly_outputs'\n",
        "MODEL_DIR.mkdir(exist_ok=True)\n",
        "OUT_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# Check dependencies\n",
        "price_model_path = MODEL_DIR / 'price_model.joblib'\n",
        "if not price_model_path.exists():\n",
        "    raise FileNotFoundError(\n",
        "        f\"File not found: {price_model_path}\\n\"\n",
        "        \"Please run 'train_price_models.ipynb' first to create the price model.\"\n",
        "    )\n",
        "\n",
        "Df = pd.read_csv(CLEAN_FILE, low_memory=False)\n",
        "pre = joblib.load(ARTIFACT_DIR / 'preprocessor.joblib')\n",
        "preprocessor = pre['preprocessor']\n",
        "NUMERIC_FEATURES = pre['numeric_features']\n",
        "CATEGORICAL_FEATURES = pre['categorical_features']\n",
        "TARGET = pre['target']\n",
        "\n",
        "X = Df[NUMERIC_FEATURES + CATEGORICAL_FEATURES]\n",
        "y = Df[TARGET].astype(float)\n",
        "\n",
        "# 1) Residual-based anomaly using best price model\n",
        "print(f\"Loading price model from: {price_model_path}\")\n",
        "price_art = joblib.load(price_model_path)\n",
        "price_model = price_art['model']\n",
        "print(f\"Price model loaded. Best model: {price_art.get('best_name', 'unknown')}\")\n",
        "\n",
        "print(\"\\n1) Computing residual-based anomalies...\")\n",
        "print(\"   Predicting prices...\")\n",
        "y_pred = price_model.predict(X)\n",
        "residual = y - y_pred\n",
        "pct_err = np.where(y_pred > 0, residual / y_pred, np.nan)\n",
        "\n",
        "Df_rb = Df.copy()\n",
        "Df_rb['price_pred'] = y_pred\n",
        "Df_rb['residual'] = residual\n",
        "Df_rb['pct_err'] = pct_err\n",
        "\n",
        "# Flag top-k% largest absolute percentage error\n",
        "k_pct = 0.05\n",
        "valid_pct_err = Df_rb['pct_err'].abs().dropna()\n",
        "if len(valid_pct_err) == 0:\n",
        "    threshold = np.nan\n",
        "else:\n",
        "    threshold = np.nanquantile(valid_pct_err, 1 - k_pct)\n",
        "Df_rb['is_anomaly_residual'] = Df_rb['pct_err'].abs() >= threshold\n",
        "num_anomalies_rb = Df_rb['is_anomaly_residual'].sum()\n",
        "print(f\"   Found {num_anomalies_rb} anomalies (top {k_pct*100}% by |pct_err|)\")\n",
        "\n",
        "rb_path = OUT_DIR / 'anomalies_residual.csv'\n",
        "Df_rb.sort_values('pct_err', key=lambda s: np.abs(s), ascending=False).to_csv(rb_path, index=False)\n",
        "print(f'   Saved residual-based anomalies to: {rb_path}')\n",
        "\n",
        "# 2) IsolationForest on transformed features + log price\n",
        "print(\"\\n2) Training IsolationForest anomaly detector...\")\n",
        "from scipy import sparse\n",
        "\n",
        "print(\"   Transforming features...\")\n",
        "Xt = preprocessor.transform(X)\n",
        "\n",
        "# Use actual price when valid, otherwise fallback to predicted price\n",
        "price_for_iso = np.where(~np.isnan(y.values) & (y.values > 0), y.values, y_pred)\n",
        "price_for_iso = np.clip(price_for_iso, a_min=0, a_max=None)\n",
        "log_price = np.log1p(price_for_iso).reshape(-1, 1)\n",
        "\n",
        "# Remove rows where transformation still produced NaN/inf\n",
        "mask_finite = np.isfinite(log_price).ravel()\n",
        "if not mask_finite.all():\n",
        "    removed = (~mask_finite).sum()\n",
        "    print(f\"   Removing {removed} rows with invalid log_price values before IsolationForest\")\n",
        "    log_price = log_price[mask_finite]\n",
        "    if sparse.issparse(Xt):\n",
        "        Xt = Xt[mask_finite]\n",
        "    else:\n",
        "        Xt = Xt[mask_finite]\n",
        "    Df_iso_base = Df.loc[mask_finite].copy()\n",
        "else:\n",
        "    Df_iso_base = Df.copy()\n",
        "\n",
        "# concat sparse Xt with dense log_price\n",
        "if sparse.issparse(Xt):\n",
        "    from scipy.sparse import hstack, csr_matrix\n",
        "    Xt_aug = hstack([Xt, csr_matrix(log_price)])\n",
        "else:\n",
        "    Xt_aug = np.hstack([Xt, log_price])\n",
        "\n",
        "print(\"   Fitting IsolationForest (contamination=0.05)...\")\n",
        "iso = IsolationForest(n_estimators=300, contamination=0.05, random_state=42, n_jobs=-1)\n",
        "iso.fit(Xt_aug)\n",
        "scores = -iso.score_samples(Xt_aug)  # higher => more anomalous\n",
        "\n",
        "Df_iso = Df_iso_base.copy()\n",
        "Df_iso['iso_score'] = scores\n",
        "\n",
        "iso_threshold = np.quantile(scores, 0.95)\n",
        "Df_iso['is_anomaly_iso'] = Df_iso['iso_score'] >= iso_threshold\n",
        "num_anomalies_iso = Df_iso['is_anomaly_iso'].sum()\n",
        "print(f\"   Found {num_anomalies_iso} anomalies (top 5% by iso_score)\")\n",
        "\n",
        "iso_model_path = MODEL_DIR / 'iso_model.joblib'\n",
        "joblib.dump({'model': iso, 'features': {'use_log_price': True}}, iso_model_path)\n",
        "print(f'   Saved IsolationForest model to: {iso_model_path}')\n",
        "\n",
        "iso_path = OUT_DIR / 'anomalies_isolation.csv'\n",
        "Df_iso.sort_values('iso_score', ascending=False).to_csv(iso_path, index=False)\n",
        "print(f'   Saved IsolationForest anomalies to: {iso_path}')\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Anomaly detection completed!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "fugue_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
